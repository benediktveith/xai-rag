## 1. High level architecture

Your system will have six main components:

1. **Corpus layer**
   Domain texts, split into chunks.

2. **Knowledge graph builder**
   Triples and entity types extracted with an LLM, stored as a KG.

3. **KG retriever**
   Given a user query, extract entities, find shortest paths between them in the KG.

4. **Path to text converter**
   Convert KG paths into natural language pseudo paragraphs.

5. **RAG answerer**
   Build a context from the pseudo paragraphs, send it to an LLM, obtain answers.

6. **KG based explainer**
   Perturb nodes, edges, or sub paths in the KG paths and measure how answers change.

---

## 2. Recommended tech stack

**Language**

* Python 3.10 or later

**Core libraries**

* `networkx` for the in memory knowledge graph
* `pydantic` or `dataclasses` for structured data
* `numpy`, `pandas` for analysis
* `tqdm` for progress bars

**LLM integration**

* OpenAI API or another provider
* Optional orchestration with LangChain or LlamaIndex, but you can also call the API directly

**Persistence**

* Triples and metadata in JSON or Parquet
* Graph in a serialized `networkx` file for prototyping
* Optional later migration to Neo4j or another graph database

---

## 3. Project structure

A simple and clean layout could look like this:

```text
kgragex/
  ├── config/
  │     └── settings.yaml
  ├── corpus/
  │     ├── raw/
  │     └── processed/
  ├── kgrag/
  │     ├── corpus_preprocessing.py
  │     ├── triple_extraction.py
  │     ├── kg_builder.py
  │     ├── query_processing.py
  │     ├── path_retrieval.py
  │     ├── path_to_text.py
  │     ├── rag_answering.py
  │     └── explanations.py
  ├── experiments/
  │     └── notebooks or scripts
  └── main.py
```

---

## 4. Step 1, prepare the corpus

### 4.1 Choose and load domain texts

Start with a small subset of your target domain, for example:

* a handful of medical articles, guidelines, or textbook sections
* or a subset of StatPearls style content if available

Load them into memory as plain text.

### 4.2 Chunk the documents

You need reasonably sized chunks that are:

* coherent paragraphs or small groups of paragraphs
* not too long for the LLM context used in triple extraction

Strategy:

* split by paragraphs or sentences
* enforce a maximum word or token length per chunk

Output format example:

```json
{
  "doc_id": "article_001",
  "chunks": [
    { "chunk_id": "article_001_0001", "text": "..." },
    { "chunk_id": "article_001_0002", "text": "..." }
  ]
}
```

Save the processed corpus as JSON files in `corpus/processed`.

---

## 5. Step 2, build the knowledge graph

### 5.1 Design the triple schema

Each triple should contain at least:

* `subject` string
* `subject_type` string, for example Disease, Symptom, Medication
* `relation` string, verb or relation phrase
* `object` string
* `object_type` string
* `doc_id`, `chunk_id` for traceability

### 5.2 LLM prompt for triple extraction

Design a clear prompt along these lines:

> You will be given a medical text. Extract factual information as triples of the form (subject, relation, object). For each subject and object, assign a semantic type such as Disease, Symptom, Medication, Body Part, Diagnostic Test, Treatment, Risk Factor, Other.
> Return a JSON array of objects with keys `subject`, `subject_type`, `relation`, `object`, `object_type`.
> Do not invent information that is not present in the text.

For each chunk:

1. Call the LLM with this prompt and the chunk text
2. Parse the JSON output
3. Attach `doc_id` and `chunk_id`
4. Validate and clean strings, for example whitespace, duplicates

### 5.3 Construct the KG with NetworkX

Use a directed graph:

* each node represents an entity string
* node attributes include at least

  * `type` (semantic label)
* each edge represents a relation between two entities
* edge attributes include at least

  * `relation`
  * `doc_id`, `chunk_id`

Basic logic:

* for each triple

  * add node for subject if not present, set `type`
  * add node for object if not present, set `type`
  * add directed edge subject to object with the relation and metadata

Persist the graph to disk using `networkx.write_gpickle` so that you do not need to rebuild it every time.

---

## 6. Step 3, query processing and path retrieval

### 6.1 Extract entities from user queries

Define a prompt for entity extraction:

> Extract all medically relevant entities from the following question, such as diseases, symptoms, anatomical structures, medications, risk factors, and tests. Return a JSON array of entity strings, no duplicates.

Implement a function:

* send the question to the LLM with this prompt
* parse the JSON array
* return the list of entity strings

### 6.2 Map query entities to KG nodes

Start simple:

* lowercase all entity names
* find exact or case insensitive matches in the graph node set
* later you can add fuzzy or embedding based matching for robustness

If you have two main entities, such as `diabetes` and `cardiovascular disease`, you can select them as:

* the first two entities that successfully map to nodes, or
* ask the LLM which two entities are most central to the question

### 6.3 Compute shortest paths in the KG

Given start and end nodes in the graph:

* use `networkx.shortest_path` to get a path of nodes
* handle the case where no path exists, for example by falling back to direct text based retrieval without the KG

From the node path, derive:

* a list of triples along the path using the edge attributes
* each path triple is enriched with node types and edge metadata

This path is now your structured reasoning chain for the query.

---

## 7. Step 4, convert KG paths into pseudo paragraphs

The goal is to transform the abstract path into human readable text that can be passed as context to an LLM.

### 7.1 Represent triples as input for the LLM

From the path triples, produce a textual summary such as:

```text
(Glucose binding, is_associated_with, Neurofibrillary tangles)
(Neurofibrillary tangles, is_associated_with, Alzheimer's disease)
(Alzheimer's disease, is_related_to, cognitive decline)
```

### 7.2 Path to paragraph prompt

Example prompt:

> You are given a sequence of triples from a medical knowledge graph. Each triple is of the form (subject, relation, object).
> Write a short, coherent paragraph in natural language that explains how these concepts are related.
> Keep the medical content accurate. Do not introduce new facts.

Send the triples text to the LLM with this prompt and obtain a paragraph.

For multiple paths:

* convert each path to its own paragraph
* concatenate them into one larger context block

---

## 8. Step 5, RAG style answer generation

Now you combine:

* the user question
* the KG derived pseudo paragraphs
* optionally, additional retrieved raw text from the corpus

### 8.1 Build the prompt

A simple structure:

```text
You are a medical question answering assistant.

Question:
<user question>

Background knowledge from a medical knowledge graph:
<pseudo paragraphs>

Use the background knowledge when answering. If something is not supported by the background, say you are not sure.

Answer:
```

Call the LLM with this prompt and return the answer.

This is your baseline RAG style answer using KG paths.

---

## 9. Step 6, KG based perturbation explanations

This is the core of KGRAG Ex style explainability.

You will measure how sensitive the answer is to the removal of specific graph components in the retrieved path.

### 9.1 Define perturbation units

Focus first on sub path level perturbations, which are triples along the path. Later you can add node and edge level perturbations separately.

For a path with triples `[t1, t2, t3, ...]`:

* sub path perturbation i
  remove triple `ti` from the path
  regenerate the pseudo paragraph
  regenerate the answer

### 9.2 Baseline and comparison

1. Generate the **baseline** answer with the full path
2. For each perturbation, generate a **perturbed** answer
3. Define a comparison function:

* for multiple choice questions, compare selected option letters
* for free text, at start a simple string comparison, later use embedding similarity thresholds

Mark a perturbation as **critical** if the answer changes.

### 9.3 Counting influence

For each triple:

* keep a counter of how many times its removal changes the answer
* the higher the count, the more influential this triple is for this query

For a single pass over the path:

* the most influential triple is the one with the highest change count
* you can also compute relative influence scores by normalizing counts

### 9.4 Explanations for end users

Build natural language explanations such as:

* Highlight the most influential triple
* Show the subject and object, with their types
* Include the source document and chunk

Example explanation:

> The most important concept in answering your question was the entity "Persistent pulmonary hypertension in the newborn".
> Removing the relation that connects it to "pulmonary hypoplasia" changed the answer multiple times during testing.
> This information was extracted from document X, section Y.

You can also display a small graph visualization where the influential nodes and edges are highlighted.

### 9.5 Technical explanations for developers

Log and optionally expose:

* which perturbation types you applied
* how many perturbations caused answer changes
* position of critical triples along the path
* node types of influential entities
* degree and betweenness centrality of influential nodes and edges

These details mirror the analysis reported in the KGRAG Ex paper.

---

## 10. Step 7, evaluation and debugging

To validate your implementation:

1. Define a small set of questions with known correct answers
2. Run the pipeline end to end
3. Check

   * answer accuracy
   * whether explanations highlight intuitively relevant entities and relations
4. Measure basic statistics

   * number of LLM calls per question
   * number of tokens
   * proportion of perturbations that change the answer

---

## 11. Suggested implementation order

To keep the effort manageable, implement in this sequence:

1. Corpus preprocessing and chunking
2. Triple extraction and KG construction
3. Simple path retrieval for two entity queries
4. Path to text conversion and RAG answer generation
5. Sub path based perturbation and explanation for a single query
6. Batch evaluation on a small dataset
7. Add node and edge level perturbations and structural analyses if needed