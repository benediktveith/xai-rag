{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CoT Explainability for RAG\n",
        "\n",
        "Dieses Notebook zeigt, wie der Explainability-Prompt mit Retrieval-Trace genutzt wird.\n",
        "\n",
        "basierend auf: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11053836&tag=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "581f5dfa",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Füge das Projektverzeichnis (mit `src/`) dem Python-Pfad hinzu, egal von wo das Notebook gestartet wird.\n",
        "project_root = next((p for p in [Path.cwd()] + list(Path.cwd().parents) if (p / 'src').exists()), None)\n",
        "if project_root is None:\n",
        "    raise RuntimeError(\"\\\"src\\\"-Verzeichnis nicht gefunden. Bitte Notebook im Projekt laufen lassen.\")\n",
        "root_str = str(project_root)\n",
        "if root_str not in sys.path:\n",
        "    sys.path.insert(0, root_str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b8dc4f52",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/MeinNotebook/xai-rag/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from src.modules.cot_explainable import CoTExplainable, ExplainableAnswer, _format_documents\n",
        "from src.modules.rag_engine import RAGEngine\n",
        "from src.modules.llm_client import LLMClient\n",
        "from src.modules.data_loader import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf56efc0",
      "metadata": {},
      "source": [
        "### Real data example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "400e59f7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Dataset found at /Users/MeinNotebook/xai-rag/data/raw/hotpot_test_fullwiki_v1.json\n",
            "Loading data into memory...\n",
            "✓ Loaded 7405 questions.\n",
            "Converting HotPotQA contexts to documents...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Articles: 100%|██████████| 7405/7405 [00:00<00:00, 33113.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Created 73774 context chunks.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "_dataLoader = DataLoader()\n",
        "documents = _dataLoader.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3626fdc0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new vector store with 73774 documents...\n",
            "Split into 73826 chunks.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m ragEngine = RAGEngine()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mragEngine\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/src/modules/rag_engine.py:46\u001b[39m, in \u001b[36mRAGEngine.setup\u001b[39m\u001b[34m(self, documents, reset, k_documents)\u001b[39m\n\u001b[32m     43\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo existing vector store found. You must provide \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to create one.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreating new vector store with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_vector_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Initialize the retriever interface\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m._retriever = \u001b[38;5;28mself\u001b[39m._vectorstore.as_retriever(\n\u001b[32m     50\u001b[39m     search_type=\u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m     search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m: k_documents} \u001b[38;5;66;03m# Adjust 'k' based on HotpotQA needs\u001b[39;00m\n\u001b[32m     52\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/src/modules/rag_engine.py:67\u001b[39m, in \u001b[36mRAGEngine._create_vector_store\u001b[39m\u001b[34m(self, documents)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSplit into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(splits)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunks.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# 2. Ingest into Chroma\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28mself\u001b[39m._vectorstore = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpersist_dir\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_chroma/vectorstores.py:1431\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, host, port, headers, chroma_cloud_api_key, tenant, database, client_settings, client, collection_metadata, collection_configuration, ssl, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1430\u001b[39m     ids = [doc.id \u001b[38;5;28;01mif\u001b[39;00m doc.id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(uuid.uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1433\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchroma_cloud_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchroma_cloud_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1450\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_chroma/vectorstores.py:1365\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, host, port, headers, chroma_cloud_api_key, tenant, database, client_settings, client, collection_metadata, collection_configuration, ssl, **kwargs)\u001b[39m\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m   1359\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m   1360\u001b[39m         api=chroma_collection._client,\n\u001b[32m   1361\u001b[39m         ids=ids,\n\u001b[32m   1362\u001b[39m         metadatas=metadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1363\u001b[39m         documents=texts,\n\u001b[32m   1364\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1368\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1371\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_chroma/vectorstores.py:627\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[32m    630\u001b[39m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[32m    631\u001b[39m     length_diff = \u001b[38;5;28mlen\u001b[39m(texts) - \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_huggingface/embeddings/huggingface.py:155\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    146\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    147\u001b[39m \n\u001b[32m    148\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \n\u001b[32m    154\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_huggingface/embeddings/huggingface.py:130\u001b[39m, in \u001b[36mHuggingFaceEmbeddings._embed\u001b[39m\u001b[34m(self, texts, encode_kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embeddings, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    137\u001b[39m     msg = (\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected embeddings to be a Tensor or a numpy array, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgot a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    140\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1130\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1128\u001b[39m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[32m   1129\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m                 embeddings = \u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m         all_embeddings.extend(embeddings)\n\u001b[32m   1134\u001b[39m all_embeddings = [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np.argsort(length_sorted_idx)]\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "ragEngine = RAGEngine()\n",
        "ragEngine.setup(documents=documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "51941321",
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(response['parsed'].answer)\n",
        "#print(response['parsed'].evidence)\n",
        "#print(response['parsed'].used_sources)\n",
        "#print(response['parsed'].reasoning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fadd4f54",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.modules.multihop_rag_engine import MultiHopRAGEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0e993f23",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to local Ollama (gemma3:1b)...\n"
          ]
        }
      ],
      "source": [
        "client = LLMClient(provider=\"ollama\", model_name=\"gemma3:1b\")\n",
        "mh_rag = MultiHopRAGEngine(rag_engine=ragEngine, llm_client=client, num_hops=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c94d175b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Multi-Hop Search for: 'Which experimental pop band has James Huggins III as a member and belongs to the Elephant 6 collective?' ---\n",
            "\n",
            "[ Hop 1 ]\n",
            "Executing search with query: 'Which experimental pop band has James Huggins III as a member and belongs to the Elephant 6 collective?'\n",
            "Generating next query...\n",
            "\n",
            "[ Hop 2 ]\n",
            "Executing search with query: 'What is the name of the recording project of James Huggins III?'\n",
            "\n",
            "Generating final answer...\n",
            "\n",
            "--- Multi-Hop Search Complete. Final Answer: James Huggins III is the recording project of James Husband, who is the multi-instrumentalist of Of Montreal. ---\n",
            "--- Multi-Hop Context: \n",
            "\n",
            " ('<doc id=\"chunk-1-1\" from_hop=\"1\" search_query=\"Which experimental pop band has James Huggins III as a member and belongs to the Elephant 6 collective?\">\\nJames Husband is the recording project of James Huggins III, Of Montreal\\'s multi-instrumentalist.\\n</doc>', ['no-source', 'chunk-1-1'])\n",
            "\n",
            " ('<doc id=\"chunk-2-1\" from_hop=\"2\" search_query=\"What is the name of the recording project of James Huggins III?\">\\nJames Husband is the recording project of James Huggins III, Of Montreal\\'s multi-instrumentalist.\\n</doc>', ['no-source', 'chunk-2-1']) ---\n"
          ]
        }
      ],
      "source": [
        "question = \"Which experimental pop band has James Huggins III as a member and belongs to the Elephant 6 collective?\"\n",
        "\n",
        "trace, all_documents = mh_rag.run_and_trace(question)\n",
        "\n",
        "final_answer = trace['final_answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cf4190b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to local Ollama (gemma3:1b)...\n"
          ]
        }
      ],
      "source": [
        "explain_client = LLMClient(provider=\"ollama\", model_name=\"gemma3:1b\", structured_output=ExplainableAnswer)\n",
        "\n",
        "explainer = CoTExplainable(llm_client=explain_client)\n",
        "response = explainer.explain(query=question, answer=final_answer, documents=all_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cfb92896",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[EvidenceItem(span='James Huggins III is the recording project of James Husband', support=['chunk-1-1'], rationale='chunk-1-1 states James Husband is the recording project of James Huggins III.'), EvidenceItem(span='who is the multi-instrumentalist of Of Montreal', support=['chunk-1-1'], rationale='chunk-1-1 states James Husband is the multi-instrumentalist of Of Montreal.')]\n",
            "[ReasoningStep(step=1, statement='The question asks for the identity of a specific experimental pop band.', support=['chunk-1-1'], support_type='direct', quote='James Huggins III is the recording project of James Husband, who is the multi-instrumentalist of Of Montreal.')]\n"
          ]
        }
      ],
      "source": [
        "print(response.evidence)\n",
        "print(response.reasoning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "eb7a6210",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('<doc id=\"chunk-1-1\" from_hop=\"1\" search_query=\"Which experimental pop band has James Huggins III as a member and belongs to the Elephant 6 collective?\">\\nJames Husband is the recording project of James Huggins III, Of Montreal\\'s multi-instrumentalist.\\n</doc>\\n<doc id=\"chunk-1-2\" from_hop=\"1\" search_query=\"Which experimental pop band has James Huggins III as a member and belongs to the Elephant 6 collective?\">\\nJames Husband is the recording project of James Huggins III, Of Montreal\\'s multi-instrumentalist.\\n</doc>', ['no-source', 'chunk-1-1', 'chunk-1-2'])\n"
          ]
        }
      ],
      "source": [
        "print(_format_documents(all_documents, from_query=question))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
