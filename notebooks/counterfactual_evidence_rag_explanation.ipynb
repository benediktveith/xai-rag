{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afc3a4b",
   "metadata": {},
   "source": [
    "# Counterfactual Evidence-Based Explanation for RAG\n",
    "\n",
    "This notebook demonstrates a post-hoc explanation method for retrieval-augmented generation (RAG) systems that focuses on **evidence support rather than semantic similarity**.\n",
    "\n",
    "Given a question and a set of retrieved documents, the system first generates a final answer using the standard RAG pipeline.  \n",
    "It then explains this answer by identifying **which parts of the retrieved documents explicitly support the answer content**.\n",
    "\n",
    "Unlike similarity-based or attention-based highlighting methods, this approach treats explanation as an **evidence verification problem**:  \n",
    "a sentence is highlighted only if it can be shown to directly support the generated answer.\n",
    "\n",
    "The method is:\n",
    "- model-agnostic and fully post-hoc\n",
    "- compatible with local LLMs (e.g. Ollama)\n",
    "- lightweight and bounded in runtime\n",
    "- designed to reduce over-highlighting and spurious evidence\n",
    "\n",
    "The resulting highlights aim to answer the question:  \n",
    "**“Which retrieved text actually justifies the answer?”**\n",
    "\n",
    "Con: we use the LLM to awnser the question of justifiying the awnser. If our LLM is poor, this can go wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a083560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root: c:\\Users\\Admin\\Desktop\\XAI\\xai-rag\n",
      "sys.path[0]: c:\\Users\\Admin\\Desktop\\XAI\\xai-rag\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Path + import hygiene\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = next((p for p in [Path.cwd()] + list(Path.cwd().parents) if (p / \"src\").exists()), None)\n",
    "if project_root is None:\n",
    "    raise RuntimeError('\"src\" directory not found. Run notebook inside the repo.')\n",
    "\n",
    "root_str = str(project_root)\n",
    "if root_str not in sys.path:\n",
    "    sys.path.insert(0, root_str)\n",
    "\n",
    "bad_markers = [\"\\\\.venv\\\\src\\\\\", \"/.venv/src/\"]\n",
    "sys.path = [p for p in sys.path if not any(m in p for m in bad_markers)]\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add9b0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.11.6 (tags/v3.11.6:8b6ee5b, Oct  2 2023, 14:57:12) [MSC v.1935 64 bit (AMD64)]\n",
      "executable: c:\\Users\\Admin\\Desktop\\XAI\\.venv\\Scripts\\python.exe\n",
      "ollama models: ['qwen3-vl:8b']\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Runtime checks (python + ollama)\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "print(\"python:\", sys.version)\n",
    "print(\"executable:\", sys.executable)\n",
    "\n",
    "r = requests.get(\"http://localhost:11434/api/tags\", timeout=10)\n",
    "r.raise_for_status()\n",
    "models = [m[\"name\"] for m in r.json().get(\"models\", [])]\n",
    "print(\"ollama models:\", models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7d0468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\XAI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Imports (project + deps)\n",
    "import re\n",
    "import html\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.modules.rag_engine import RAGEngine\n",
    "from src.modules.llm_client import LLMClient\n",
    "from src.modules.data_loader_single_hop import BoolQDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c79bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Config\n",
    "OLLAMA_MODEL = \"qwen3-vl:8b\"   # set to one of your /api/tags models\n",
    "PERSIST_DIR = \"../data/vector_db_bool\"\n",
    "\n",
    "TOP_K_DOCS = 4\n",
    "MAX_SENTENCES_PER_DOC = 10      # cap work\n",
    "MAX_SUPPORT_PER_CLAIM = 2       # reduce over-highlighting\n",
    "\n",
    "print(\"Config loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ea84ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded documents: 9427\n",
      "Loading existing vector store from ../data/vector_db_bool...\n",
      "RagEngine ready.\n",
      "Connecting to local Ollama (qwen3-vl:8b)...\n",
      "READY\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load data + build vector DB\n",
    "data_loader = BoolQDataLoader()\n",
    "documents = data_loader.setup()\n",
    "print(\"loaded documents:\", len(documents))\n",
    "\n",
    "rag = RAGEngine(persist_dir=PERSIST_DIR)\n",
    "rag.setup(documents=documents)\n",
    "\n",
    "client = LLMClient(provider=\"ollama\", model_name=OLLAMA_MODEL)\n",
    "llm = client.get_llm()\n",
    "\n",
    "print(\"READY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a1bc53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved docs: 4\n",
      "\n",
      "--- DOC 0 ---\n",
      "The Burj Al Arab (Arabic: برج العرب‎, Tower of the Arabs) is a luxury hotel located in Dubai, United Arab Emirates. It is the third tallest hotel in the world (although 39% of its total height is made up of non-occupiable space). Burj Al Arab stands on an artificial island 280 m (920 ft) from Jumeirah Beach and is connected to the mainland by a private curving bridge. The shape of the structure is designed to resemble the sail of a ship. It has a helipad near the roof at a height of 210 m (689 f\n",
      "\n",
      "--- DOC 1 ---\n",
      "The Tower of Terror buildings are among the tallest structures found at their respective Disney resorts. At 199 feet (60.7 m), the Florida version is the second tallest attraction at the Walt Disney World Resort, with only Expedition Everest 199.5 feet (60.8 m) being taller. At the Disneyland Resort, the 183-foot (55.8 m) structure (which now houses Guardians of the Galaxy -- Mission: Breakout!) is the tallest building at the resort, as well as one of the tallest buildings in Anaheim. At Disneyl\n",
      "\n",
      "--- DOC 2 ---\n",
      "The world's tallest artificial structure is the 829.8-metre-tall (2,722 ft) Burj Khalifa in Dubai (of the United Arab Emirates). The building gained the official title of ``Tallest Building in the World'' and the tallest self-supported structure at its opening on January 9, 2010. The second-tallest self-supporting structure and the tallest tower is the Tokyo Skytree. The tallest guyed structure is the KVLY-TV mast. Breetsky was the third building, which was surpassed by Tokyo in 1987.\n",
      "\n",
      "--- DOC 3 ---\n",
      "The Burj Khalifa (Arabic: برج خليفة‎, Arabic for ``Khalifa Tower''; pronounced English: /ˈbɜːrdʒ kəˈliːfə/), known as the Burj Dubai prior to its inauguration in 2010, is a skyscraper in Dubai, United Arab Emirates. With a total height of 829.8 m (2,722 ft) and a roof height (excluding antenna) of 828 m (2,717 ft), the Burj Khalifa has been the tallest structure and building in the world since its topping out in late 2008.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Ask question + retrieve docs\n",
    "question = \"What is the thrid tallest hotel in the world?\"\n",
    "\n",
    "docs = rag.retrieve_documents(question)\n",
    "docs = docs[:TOP_K_DOCS]\n",
    "\n",
    "print(\"retrieved docs:\", len(docs))\n",
    "for i, d in enumerate(docs):\n",
    "    print(\"\\n--- DOC\", i, \"---\")\n",
    "    print((d.page_content or \"\")[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54872bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the thrid tallest hotel in the world?\n",
      "baseline: Burj Al Arab\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Baseline answer (context-only)\n",
    "context = \"\\n\\n\".join(d.page_content for d in docs if d.page_content)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Answer using only the context.\n",
    "If the answer is missing, say unknown.\n",
    "Return only the final answer.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Question: \", question)\n",
    "\n",
    "baseline = llm.invoke(prompt).content.strip()\n",
    "print(\"baseline:\", baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d9326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Sentence splitter + HTML highlight helpers\n",
    "def split_sentences(text: str):\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    return [s.strip() for s in re.split(r\"(?<=[.!?])\\s+\", text) if s.strip()]\n",
    "\n",
    "def _find_all_spans(text: str, needle: str):\n",
    "    spans = []\n",
    "    if not needle:\n",
    "        return spans\n",
    "    start = 0\n",
    "    n = len(needle)\n",
    "    while True:\n",
    "        idx = text.find(needle, start)\n",
    "        if idx == -1:\n",
    "            break\n",
    "        spans.append((idx, idx + n))\n",
    "        start = idx + max(1, n)\n",
    "    return spans\n",
    "\n",
    "def _merge_spans(spans):\n",
    "    if not spans:\n",
    "        return []\n",
    "    spans = sorted(spans, key=lambda x: (x[0], x[1]))\n",
    "    merged = [spans[0]]\n",
    "    for s, e in spans[1:]:\n",
    "        ps, pe = merged[-1]\n",
    "        if s <= pe:\n",
    "            merged[-1] = (ps, max(pe, e))\n",
    "        else:\n",
    "            merged.append((s, e))\n",
    "    return merged\n",
    "\n",
    "def highlight_html_exact(text: str, snippets):\n",
    "    spans = []\n",
    "    for snip in snippets:\n",
    "        snip = (snip or \"\").strip()\n",
    "        if not snip:\n",
    "            continue\n",
    "        spans.extend(_find_all_spans(text, snip))\n",
    "    spans = _merge_spans(spans)\n",
    "\n",
    "    out = []\n",
    "    last = 0\n",
    "    for s, e in spans:\n",
    "        out.append(html.escape(text[last:s]))\n",
    "        out.append(\"<mark>\")\n",
    "        out.append(html.escape(text[s:e]))\n",
    "        out.append(\"</mark>\")\n",
    "        last = e\n",
    "    out.append(html.escape(text[last:]))\n",
    "    return \"\".join(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d5aab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claims: ['Burj Al Arab']\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Claim extraction (simple and strict)\n",
    "def extract_claims(answer: str):\n",
    "    a = (answer or \"\").strip()\n",
    "    if not a or a.lower() == \"unknown\":\n",
    "        return []\n",
    "    # For short answers like a color, treat as one claim\n",
    "    return [a]\n",
    "\n",
    "claims = extract_claims(baseline)\n",
    "print(\"claims:\", claims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1381d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support checker ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Support check prompt (strict entailment)\n",
    "def support_check(claim: str, sentence: str):\n",
    "    check_prompt = f\"\"\"\n",
    "You are verifying evidence support.\n",
    "\n",
    "Claim:\n",
    "{claim}\n",
    "\n",
    "Evidence sentence:\n",
    "{sentence}\n",
    "\n",
    "Decide if the evidence sentence explicitly supports the claim.\n",
    "Reply with exactly one token: YES or NO.\n",
    "\"\"\".strip()\n",
    "\n",
    "    out = llm.invoke(check_prompt).content.strip().upper()\n",
    "    return out.startswith(\"YES\")\n",
    "\n",
    "print(\"Support checker ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a168886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc 0 candidates: 5\n",
      "doc 1 candidates: 4\n",
      "doc 2 candidates: 5\n",
      "doc 3 candidates: 2\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Candidate sentences (cheap prefilter)\n",
    "def candidate_sentences(docs, max_sents_per_doc: int):\n",
    "    per_doc = {}\n",
    "    for i, d in enumerate(docs):\n",
    "        sents = split_sentences(d.page_content)\n",
    "        per_doc[i] = sents[:max_sents_per_doc]\n",
    "    return per_doc\n",
    "\n",
    "cands_by_doc = candidate_sentences(docs, MAX_SENTENCES_PER_DOC)\n",
    "for di, sents in cands_by_doc.items():\n",
    "    print(\"doc\", di, \"candidates:\", len(sents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25560ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking evidence support: 100%|██████████| 16/16 [16:18<00:00, 61.13s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ['Burj Al Arab stands on an artificial island 280 m (920 ft) from Jumeirah Beach and is connected to the mainland by a private curving bridge.'],\n",
       " 1: [],\n",
       " 2: [],\n",
       " 3: []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 12: Evidence selection per claim (with progress bar)\n",
    "highlights_by_doc = {i: [] for i in range(len(docs))}\n",
    "\n",
    "total_checks = sum(len(sents) for sents in cands_by_doc.values()) * max(1, len(claims))\n",
    "pbar = tqdm(total=total_checks, desc=\"Checking evidence support\")\n",
    "\n",
    "for claim in claims:\n",
    "    found = 0\n",
    "    for doc_idx, sents in cands_by_doc.items():\n",
    "        for sent in sents:\n",
    "            pbar.update(1)\n",
    "\n",
    "            if support_check(claim, sent):\n",
    "                highlights_by_doc[doc_idx].append(sent)\n",
    "                found += 1\n",
    "                if found >= MAX_SUPPORT_PER_CLAIM:\n",
    "                    break\n",
    "\n",
    "        if found >= MAX_SUPPORT_PER_CLAIM:\n",
    "            break\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "for i in highlights_by_doc:\n",
    "    highlights_by_doc[i] = list(dict.fromkeys(highlights_by_doc[i]))\n",
    " \n",
    "highlights_by_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ce76f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>mark{padding:0.08em 0.15em; border-radius:3px;}</style><h2>Answer</h2><div style='white-space: pre-wrap;'>Burj Al Arab</div><hr/><h2>Retrieved Documents</h2><p>Highlights are sentences that explicitly support the claim.</p><h3>Document 0</h3><div style='white-space: pre-wrap; border: 1px solid #ddd; padding: 10px; border-radius: 6px;'>The Burj Al Arab (Arabic: برج العرب‎, Tower of the Arabs) is a luxury hotel located in Dubai, United Arab Emirates. It is the third tallest hotel in the world (although 39% of its total height is made up of non-occupiable space). <mark>Burj Al Arab stands on an artificial island 280 m (920 ft) from Jumeirah Beach and is connected to the mainland by a private curving bridge.</mark> The shape of the structure is designed to resemble the sail of a ship. It has a helipad near the roof at a height of 210 m (689 ft) above ground.</div><br/><h3>Document 1</h3><div style='white-space: pre-wrap; border: 1px solid #ddd; padding: 10px; border-radius: 6px;'>The Tower of Terror buildings are among the tallest structures found at their respective Disney resorts. At 199 feet (60.7 m), the Florida version is the second tallest attraction at the Walt Disney World Resort, with only Expedition Everest 199.5 feet (60.8 m) being taller. At the Disneyland Resort, the 183-foot (55.8 m) structure (which now houses Guardians of the Galaxy -- Mission: Breakout!) is the tallest building at the resort, as well as one of the tallest buildings in Anaheim. At Disneyland Paris, it is the second tallest attraction.</div><br/><h3>Document 2</h3><div style='white-space: pre-wrap; border: 1px solid #ddd; padding: 10px; border-radius: 6px;'>The world&#x27;s tallest artificial structure is the 829.8-metre-tall (2,722 ft) Burj Khalifa in Dubai (of the United Arab Emirates). The building gained the official title of ``Tallest Building in the World&#x27;&#x27; and the tallest self-supported structure at its opening on January 9, 2010. The second-tallest self-supporting structure and the tallest tower is the Tokyo Skytree. The tallest guyed structure is the KVLY-TV mast. Breetsky was the third building, which was surpassed by Tokyo in 1987.</div><br/><h3>Document 3</h3><div style='white-space: pre-wrap; border: 1px solid #ddd; padding: 10px; border-radius: 6px;'>The Burj Khalifa (Arabic: برج خليفة‎, Arabic for ``Khalifa Tower&#x27;&#x27;; pronounced English: /ˈbɜːrdʒ kəˈliːfə/), known as the Burj Dubai prior to its inauguration in 2010, is a skyscraper in Dubai, United Arab Emirates. With a total height of 829.8 m (2,722 ft) and a roof height (excluding antenna) of 828 m (2,717 ft), the Burj Khalifa has been the tallest structure and building in the world since its topping out in late 2008.</div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 13: Render output\n",
    "parts = []\n",
    "parts.append(\"<style>mark{padding:0.08em 0.15em; border-radius:3px;}</style>\")\n",
    "parts.append(\"<h2>Answer</h2>\")\n",
    "parts.append(f\"<div style='white-space: pre-wrap;'>{html.escape(baseline)}</div>\")\n",
    "parts.append(\"<hr/>\")\n",
    "\n",
    "parts.append(\"<h2>Retrieved Documents</h2>\")\n",
    "parts.append(\"<p>Highlights are sentences that explicitly support the claim.</p>\")\n",
    "\n",
    "for i, d in enumerate(docs):\n",
    "    snippets = highlights_by_doc.get(i, [])\n",
    "    body = highlight_html_exact(d.page_content, snippets) if snippets else html.escape(d.page_content)\n",
    "\n",
    "    parts.append(f\"<h3>Document {i}</h3>\")\n",
    "    parts.append(\"<div style='white-space: pre-wrap; border: 1px solid #ddd; padding: 10px; border-radius: 6px;'>\")\n",
    "    parts.append(body)\n",
    "    parts.append(\"</div><br/>\")\n",
    "\n",
    "display(HTML(\"\".join(parts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a949751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_idx</th>\n",
       "      <th>highlighted_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Burj Al Arab stands on an artificial island 28...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_idx                               highlighted_sentence\n",
       "0        0  Burj Al Arab stands on an artificial island 28..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 14: Simple table for debugging\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for doc_idx, sents in highlights_by_doc.items():\n",
    "    for s in sents:\n",
    "        rows.append({\n",
    "            \"doc_idx\": doc_idx,\n",
    "            \"highlighted_sentence\": s\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6ec882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a7b3433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Answer</h2><p>Burj Al Arab</p><hr><h3>Document 0</h3><pre>The Burj Al Arab (Arabic: برج العرب‎, Tower of the Arabs) is a luxury hotel located in Dubai, United Arab Emirates. It is the third tallest hotel in the world (although 39% of its total height is made up of non-occupiable space). <mark>Burj Al Arab stands on an artificial island 280 m (920 ft) from Jumeirah Beach and is connected to the mainland by a private curving bridge.</mark> The shape of the structure is designed to resemble the sail of a ship. It has a helipad near the roof at a height of 210 m (689 ft) above ground.</pre><h3>Document 1</h3><pre>The Tower of Terror buildings are among the tallest structures found at their respective Disney resorts. At 199 feet (60.7 m), the Florida version is the second tallest attraction at the Walt Disney World Resort, with only Expedition Everest 199.5 feet (60.8 m) being taller. At the Disneyland Resort, the 183-foot (55.8 m) structure (which now houses Guardians of the Galaxy -- Mission: Breakout!) is the tallest building at the resort, as well as one of the tallest buildings in Anaheim. At Disneyland Paris, it is the second tallest attraction.</pre><h3>Document 2</h3><pre>The world&#x27;s tallest artificial structure is the 829.8-metre-tall (2,722 ft) Burj Khalifa in Dubai (of the United Arab Emirates). The building gained the official title of ``Tallest Building in the World&#x27;&#x27; and the tallest self-supported structure at its opening on January 9, 2010. The second-tallest self-supporting structure and the tallest tower is the Tokyo Skytree. The tallest guyed structure is the KVLY-TV mast. Breetsky was the third building, which was surpassed by Tokyo in 1987.</pre><h3>Document 3</h3><pre>The Burj Khalifa (Arabic: برج خليفة‎, Arabic for ``Khalifa Tower&#x27;&#x27;; pronounced English: /ˈbɜːrdʒ kəˈliːfə/), known as the Burj Dubai prior to its inauguration in 2010, is a skyscraper in Dubai, United Arab Emirates. With a total height of 829.8 m (2,722 ft) and a roof height (excluding antenna) of 828 m (2,717 ft), the Burj Khalifa has been the tallest structure and building in the world since its topping out in late 2008.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def highlight_text(text, snippets):\n",
    "    out = html.escape(text)\n",
    "    for s in snippets:\n",
    "        out = out.replace(\n",
    "            html.escape(s),\n",
    "            f\"<mark>{html.escape(s)}</mark>\"\n",
    "        )\n",
    "    return out\n",
    "\n",
    "html_out = \"<h2>Answer</h2>\"\n",
    "html_out += f\"<p>{html.escape(baseline)}</p><hr>\"\n",
    "\n",
    "for i, d in enumerate(docs):\n",
    "    html_out += f\"<h3>Document {i}</h3>\"\n",
    "    body = highlight_text(d.page_content, highlights_by_doc.get(i, []))\n",
    "    html_out += f\"<pre>{body}</pre>\"\n",
    "\n",
    "display(HTML(html_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d7d7fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlighted sentence indices: [2]\n"
     ]
    }
   ],
   "source": [
    "# We prepare helpers for removing/keeping evidence and mapping highlights to sentence indices.\n",
    "# We assume highlights mark full sentences.\n",
    "\n",
    "def mask_remove(indices, sentences):\n",
    "    return \" \".join([s for i, s in enumerate(sentences) if i not in indices])\n",
    "\n",
    "def mask_except(indices, sentences):\n",
    "    return \" \".join([s for i, s in enumerate(sentences) if i in indices])\n",
    "\n",
    "def get_highlight_indices(sentences, highlights_by_doc):\n",
    "    hl = set()\n",
    "    for doc_sents in highlights_by_doc.values():\n",
    "        for h in doc_sents:\n",
    "            for i, s in enumerate(sentences):\n",
    "                if h.strip() == s.strip():\n",
    "                    hl.add(i)\n",
    "    return sorted(list(hl))\n",
    "\n",
    "sentences_full = split_sentences(context)\n",
    "highlight_indices = get_highlight_indices(sentences_full, highlights_by_doc)\n",
    "print(\"highlighted sentence indices:\", highlight_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c1bbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': 'Burj Al Arab',\n",
       " 'comp_answer': 'Burj Al Arab',\n",
       " 'suff_answer': 'unknown',\n",
       " 'comprehensiveness_drop': 0,\n",
       " 'sufficiency_drop': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We measure drop when removing highlights (comprehensiveness) and when keeping only highlights (sufficiency).\n",
    "# We compare answers relative to the baseline.\n",
    "\n",
    "def answer_from_context(question, ctx):\n",
    "    p = f\"\"\"Answer using only the context.\n",
    "If the answer is missing, say unknown.\n",
    "Return only the final answer.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "{ctx}\n",
    "\n",
    "Answer:\"\"\".strip()\n",
    "    return llm.invoke(p).content.strip()\n",
    "\n",
    "def run_comp_suff(question, context, highlight_indices):\n",
    "    sentences = split_sentences(context)\n",
    "    baseline = answer_from_context(question, context)\n",
    "\n",
    "    ctx_comp = mask_remove(highlight_indices, sentences)\n",
    "    ans_comp = answer_from_context(question, ctx_comp)\n",
    "    comp_drop = 1 if ans_comp != baseline else 0\n",
    "\n",
    "    ctx_suff = mask_except(highlight_indices, sentences) if highlight_indices else \"\"\n",
    "    ans_suff = answer_from_context(question, ctx_suff) if ctx_suff else \"unknown\"\n",
    "    suff_drop = 1 if ans_suff != baseline else 0\n",
    "\n",
    "    return {\n",
    "        \"baseline\": baseline,\n",
    "        \"comp_answer\": ans_comp,\n",
    "        \"suff_answer\": ans_suff,\n",
    "        \"comprehensiveness_drop\": comp_drop,\n",
    "        \"sufficiency_drop\": suff_drop,\n",
    "    }\n",
    "\n",
    "res = run_comp_suff(question, context, highlight_indices)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e824730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fast sweep: 100%|██████████| 5/5 [36:44<00:00, 440.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg comprehensiveness drop: 0.6\n",
      "avg sufficiency drop: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CacheInfo' object has no attribute 'cache'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mavg comprehensiveness drop:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(mean(comp_scores), \u001b[32m3\u001b[39m))\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mavg sufficiency drop:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(mean(suff_scores), \u001b[32m3\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLLM cache size:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mllm_cached\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache\u001b[49m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'CacheInfo' object has no attribute 'cache'"
     ]
    }
   ],
   "source": [
    "# Faster sweep: caching, fewer LLM calls, capped sentences, fewer questions.\n",
    "\n",
    "import random\n",
    "from statistics import mean\n",
    "from functools import lru_cache\n",
    "\n",
    "# global cache for any LLM call (same prompt -> instant result)\n",
    "@lru_cache(maxsize=4096)\n",
    "def llm_cached(prompt):\n",
    "    return llm.invoke(prompt).content.strip()\n",
    "\n",
    "def answer_from_context_cached(q, ctx):\n",
    "    p = f\"\"\"Answer using only the context.\n",
    "If the answer is missing, say unknown.\n",
    "Return only the final answer.\n",
    "\n",
    "Question: {q}\n",
    "\n",
    "Context:\n",
    "{ctx}\n",
    "\n",
    "Answer:\"\"\".strip()\n",
    "    return llm_cached(p)\n",
    "\n",
    "@lru_cache(maxsize=4096)\n",
    "def support_check_cached(claim, sentence):\n",
    "    check_prompt = f\"\"\"You are verifying evidence support.\n",
    "\n",
    "Claim:\n",
    "{claim}\n",
    "\n",
    "Evidence sentence:\n",
    "{sentence}\n",
    "\n",
    "Decide if the evidence sentence explicitly supports the claim.\n",
    "Reply with exactly one token: YES or NO.\"\"\"\n",
    "    return llm_cached(check_prompt).upper().startswith(\"YES\")\n",
    "\n",
    "\n",
    "def run_one_fast(q):\n",
    "    docs = rag.retrieve_documents(q)[:TOP_K_DOCS]\n",
    "    ctx = \"\\n\\n\".join(d.page_content for d in docs if d.page_content)\n",
    "\n",
    "    baseline = answer_from_context_cached(q, ctx)\n",
    "    claims = extract_claims(baseline)\n",
    "\n",
    "    cands = candidate_sentences(docs, min(5, MAX_SENTENCES_PER_DOC))\n",
    "\n",
    "    hb = {i: [] for i in range(len(docs))}\n",
    "    for claim in claims[:1]:  # only first claim to save time\n",
    "        found = 0\n",
    "        for di, sents in cands.items():\n",
    "            for s in sents[:5]:\n",
    "                if support_check_cached(claim, s):\n",
    "                    hb[di].append(s)\n",
    "                    found += 1\n",
    "                    if found >= 1:\n",
    "                        break\n",
    "            if found >= 1:\n",
    "                break\n",
    "\n",
    "    sents_full = split_sentences(ctx)\n",
    "    idxs = get_highlight_indices(sents_full, hb)\n",
    "\n",
    "    r = run_comp_suff(q, ctx, idxs)\n",
    "    return r[\"comprehensiveness_drop\"], r[\"sufficiency_drop\"]\n",
    "\n",
    "\n",
    "qa_questions = get_questions_from_loader(data_loader, n=5)\n",
    "random.shuffle(qa_questions)\n",
    "\n",
    "comp_scores, suff_scores = [], []\n",
    "\n",
    "for q in tqdm(qa_questions, desc=\"fast sweep\"):\n",
    "    c, s = run_one_fast(q)\n",
    "    comp_scores.append(c)\n",
    "    suff_scores.append(s)\n",
    "\n",
    "print(\"avg comprehensiveness drop:\", round(mean(comp_scores), 3))\n",
    "print(\"avg sufficiency drop:\", round(mean(suff_scores), 3))\n",
    "info = llm_cached.cache_info()\n",
    "print(\"LLM cache — hits:\", info.hits, \"misses:\", info.misses, \"current:\", info.currsize, \"max:\", info.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce682d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM cache — hits: 0 misses: 29 current: 29 max: 4096\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
