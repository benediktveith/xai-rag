{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afc3a4b",
   "metadata": {},
   "source": [
    "# Counterfactual Evidence-Based Explanation for RAG\n",
    "\n",
    "This notebook demonstrates a post-hoc explanation method for retrieval-augmented generation (RAG) systems that focuses on **evidence support rather than semantic similarity**.\n",
    "\n",
    "Given a question and a set of retrieved documents, the system first generates a final answer using the standard RAG pipeline.  \n",
    "It then explains this answer by identifying **which parts of the retrieved documents explicitly support the answer content**.\n",
    "\n",
    "Unlike similarity-based or attention-based highlighting methods, this approach treats explanation as an **evidence verification problem**:  \n",
    "a sentence is highlighted only if it can be shown to directly support the generated answer.\n",
    "\n",
    "The method is:\n",
    "- model-agnostic and fully post-hoc\n",
    "- compatible with local LLMs (e.g. Ollama)\n",
    "- lightweight and bounded in runtime\n",
    "- designed to reduce over-highlighting and spurious evidence\n",
    "\n",
    "The resulting highlights aim to answer the question:  \n",
    "**“Which retrieved text actually justifies the answer?”**\n",
    "\n",
    "Con: we use the LLM to awnser the question of justifiying the awnser. If our LLM is poor, this can go wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a083560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root: c:\\Users\\Admin\\Desktop\\XAI\\FINAL\\xai-rag\n",
      "sys.path[0]: c:\\Users\\Admin\\Desktop\\XAI\\FINAL\\xai-rag\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Path + import hygiene\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = next((p for p in [Path.cwd()] + list(Path.cwd().parents) if (p / \"src\").exists()), None)\n",
    "if project_root is None:\n",
    "    raise RuntimeError('\"src\" directory not found. Run notebook inside the repo.')\n",
    "\n",
    "root_str = str(project_root)\n",
    "if root_str not in sys.path:\n",
    "    sys.path.insert(0, root_str)\n",
    "\n",
    "bad_markers = [\"\\\\.venv\\\\src\\\\\", \"/.venv/src/\"]\n",
    "sys.path = [p for p in sys.path if not any(m in p for m in bad_markers)]\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "add9b0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.11.6 (tags/v3.11.6:8b6ee5b, Oct  2 2023, 14:57:12) [MSC v.1935 64 bit (AMD64)]\n",
      "executable: c:\\Users\\Admin\\Desktop\\XAI\\FINAL\\xai-rag\\.venv\\Scripts\\python.exe\n",
      "ollama models: ['qwen3-vl:8b']\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Runtime checks (python + ollama)\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "print(\"python:\", sys.version)\n",
    "print(\"executable:\", sys.executable)\n",
    "\n",
    "r = requests.get(\"http://localhost:11434/api/tags\", timeout=10)\n",
    "r.raise_for_status()\n",
    "models = [m[\"name\"] for m in r.json().get(\"models\", [])]\n",
    "print(\"ollama models:\", models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd7d0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Imports (project + deps)\n",
    "import re\n",
    "import html\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.modules.rag.rag_engine import RAGEngine\n",
    "from src.modules.llm.llm_client import LLMClient\n",
    "from src.modules.loader.data_loader_single_hop import BoolQDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0c79bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Config\n",
    "OLLAMA_MODEL = \"qwen3-vl:8b\"   # set to one of your /api/tags models\n",
    "PERSIST_DIR = \"../data/vector_db_bool\"\n",
    "\n",
    "TOP_K_DOCS = 4\n",
    "MAX_SENTENCES_PER_DOC = 10      # cap work\n",
    "MAX_SUPPORT_PER_CLAIM = 2       # reduce over-highlighting\n",
    "\n",
    "print(\"Config loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56ea84ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded documents: 9427\n",
      "Loading existing vector store from ../data/vector_db_bool...\n",
      "RagEngine ready.\n",
      "Connecting to local Ollama (qwen3-vl:8b)...\n",
      "READY\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load data + build vector DB\n",
    "data_loader = BoolQDataLoader()\n",
    "documents = data_loader.setup()\n",
    "print(\"loaded documents:\", len(documents))\n",
    "\n",
    "rag = RAGEngine(persist_dir=PERSIST_DIR)\n",
    "rag.setup(documents=documents)\n",
    "\n",
    "client = LLMClient(provider=\"ollama\", model_name=OLLAMA_MODEL)\n",
    "llm = client.get_llm()\n",
    "\n",
    "print(\"READY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a1bc53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved docs: 4\n",
      "\n",
      "--- DOC 0 ---\n",
      "The Tower of Terror buildings are among the tallest structures found at their respective Disney resorts. At 199 feet (60.7 m), the Florida version is the second tallest attraction at the Walt Disney World Resort, with only Expedition Everest 199.5 feet (60.8 m) being taller. At the Disneyland Resort, the 183-foot (55.8 m) structure (which now houses Guardians of the Galaxy -- Mission: Breakout!) is the tallest building at the resort, as well as one of the tallest buildings in Anaheim. At Disneyl\n",
      "\n",
      "--- DOC 1 ---\n",
      "New York City, the most populous city in the United States, is home to over 6,486 completed high rise buildings of at least 35 meters, of which at least 113 completed are taller than 600 feet (183 m). The tallest building in New York is One World Trade Center, which rises 1,776 feet (541 m). The 104-story skyscraper also stands as the tallest building in the United States, the tallest building in the Western Hemisphere, and the sixth-tallest building in the world. The second-tallest building in \n",
      "\n",
      "--- DOC 2 ---\n",
      "The Tokyo Skytree, completed in February 2012, reaches a height of 634 m (2,080 ft), making it the tallest tower, and second-tallest free-standing structure in the world.\n",
      "\n",
      "--- DOC 3 ---\n",
      "Eureka Tower is a 297.3-metre (975 ft) skyscraper located in the Southbank precinct of Melbourne, Victoria, Australia. Construction began in August 2002 and the exterior completed on 1 June 2006. The plaza was finished in June 2006 and the building was officially opened on 11 October 2006. The project was designed by Melbourne architectural firm Fender Katsalidis Architects and was built by Grocon (Grollo Australia). The developer of the tower was Eureka Tower Pty Ltd, a joint venture consisting\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Ask question + retrieve docs\n",
    "question = \"What building is 199 feet tall?\"\n",
    "\n",
    "docs = rag.retrieve_documents(question)\n",
    "docs = docs[:TOP_K_DOCS]\n",
    "\n",
    "print(\"retrieved docs:\", len(docs))\n",
    "for i, d in enumerate(docs):\n",
    "    print(\"\\n--- DOC\", i, \"---\")\n",
    "    print((d.page_content or \"\")[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54872bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What building is 199 feet tall?\n",
      "baseline: Tower of Terror\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Baseline answer (context-only)\n",
    "context = \"\\n\\n\".join(d.page_content for d in docs if d.page_content)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Answer using only the context.\n",
    "If the answer is missing, say unknown.\n",
    "Return only the final answer.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Question: \", question)\n",
    "\n",
    "baseline = llm.invoke(prompt).content.strip()\n",
    "print(\"baseline:\", baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4d9326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Sentence splitter + HTML highlight helpers\n",
    "def split_sentences(text: str):\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    return [s.strip() for s in re.split(r\"(?<=[.!?])\\s+\", text) if s.strip()]\n",
    "\n",
    "def _find_all_spans(text: str, needle: str):\n",
    "    spans = []\n",
    "    if not needle:\n",
    "        return spans\n",
    "    start = 0\n",
    "    n = len(needle)\n",
    "    while True:\n",
    "        idx = text.find(needle, start)\n",
    "        if idx == -1:\n",
    "            break\n",
    "        spans.append((idx, idx + n))\n",
    "        start = idx + max(1, n)\n",
    "    return spans\n",
    "\n",
    "def _merge_spans(spans):\n",
    "    if not spans:\n",
    "        return []\n",
    "    spans = sorted(spans, key=lambda x: (x[0], x[1]))\n",
    "    merged = [spans[0]]\n",
    "    for s, e in spans[1:]:\n",
    "        ps, pe = merged[-1]\n",
    "        if s <= pe:\n",
    "            merged[-1] = (ps, max(pe, e))\n",
    "        else:\n",
    "            merged.append((s, e))\n",
    "    return merged\n",
    "\n",
    "def highlight_html_exact(text: str, snippets):\n",
    "    spans = []\n",
    "    for snip in snippets:\n",
    "        snip = (snip or \"\").strip()\n",
    "        if not snip:\n",
    "            continue\n",
    "        spans.extend(_find_all_spans(text, snip))\n",
    "    spans = _merge_spans(spans)\n",
    "\n",
    "    out = []\n",
    "    last = 0\n",
    "    for s, e in spans:\n",
    "        out.append(html.escape(text[last:s]))\n",
    "        out.append(\"<mark>\")\n",
    "        out.append(html.escape(text[s:e]))\n",
    "        out.append(\"</mark>\")\n",
    "        last = e\n",
    "    out.append(html.escape(text[last:]))\n",
    "    return \"\".join(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20d5aab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claims: ['Tower of Terror']\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Claim extraction (simple and strict)\n",
    "def extract_claims(answer: str):\n",
    "    a = (answer or \"\").strip()\n",
    "    if not a or a.lower() == \"unknown\":\n",
    "        return []\n",
    "    # For short answers like a color, treat as one claim\n",
    "    return [a]\n",
    "\n",
    "claims = extract_claims(baseline)\n",
    "print(\"claims:\", claims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1381d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support checker ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Support check prompt (strict entailment)\n",
    "def support_check(claim: str, window: str):\n",
    "    check_prompt = f\"\"\"\n",
    "You are verifying evidence support.\n",
    "\n",
    "Claim:\n",
    "{claim}\n",
    "\n",
    "Evidence context:\n",
    "{window}\n",
    "\n",
    "Decide if the evidence context explicitly supports the claim.\n",
    "Reply with exactly one token: YES or NO.\n",
    "\"\"\".strip()\n",
    "\n",
    "    out = llm.invoke(check_prompt).content.strip().upper()\n",
    "    return out.startswith(\"YES\")\n",
    "\n",
    "print(\"Support checker ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a168886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc 0 candidates: 4\n",
      "doc 1 candidates: 6\n",
      "doc 2 candidates: 1\n",
      "doc 3 candidates: 8\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Candidate sentences (cheap prefilter)\n",
    "def candidate_windows(docs, max_sents_per_doc: int, window_size: int = 3):\n",
    "    per_doc = {}\n",
    "    for i, d in enumerate(docs):\n",
    "        sents = split_sentences(d.page_content)[:max_sents_per_doc]\n",
    "        windows = []\n",
    "        for idx in range(len(sents)):\n",
    "            start = max(0, idx - (window_size - 1))\n",
    "            window = \" \".join(sents[start:idx+1])\n",
    "            windows.append({\n",
    "                \"sentence\": sents[idx],\n",
    "                \"window\": window,\n",
    "                \"sent_idx\": idx\n",
    "            })\n",
    "        per_doc[i] = windows\n",
    "    return per_doc\n",
    "\n",
    "cands_by_doc = candidate_windows(docs, MAX_SENTENCES_PER_DOC, window_size=3)\n",
    "\n",
    "for di, items in cands_by_doc.items():\n",
    "    print(\"doc\", di, \"candidates:\", len(items))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25560ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking evidence support:  16%|█▌        | 3/19 [01:44<09:18, 34.88s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ['At 199 feet (60.7 m), the Florida version is the second tallest attraction at the Walt Disney World Resort, with only Expedition Everest 199.5 feet (60.8 m) being taller.',\n",
       "  'At the Disneyland Resort, the 183-foot (55.8 m) structure (which now houses Guardians of the Galaxy -- Mission: Breakout!) is the tallest building at the resort, as well as one of the tallest buildings in Anaheim.'],\n",
       " 1: [],\n",
       " 2: [],\n",
       " 3: []}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 12: Evidence selection per claim (with progress bar)\n",
    "highlights_by_doc = {i: [] for i in range(len(docs))}\n",
    "\n",
    "total_checks = sum(len(items) for items in cands_by_doc.values()) * max(1, len(claims))\n",
    "pbar = tqdm(total=total_checks, desc=\"Checking evidence support\")\n",
    "\n",
    "for claim in claims:\n",
    "    found = 0\n",
    "    for doc_idx, items in cands_by_doc.items():\n",
    "        for item in items:\n",
    "            pbar.update(1)\n",
    "\n",
    "            if support_check(claim, item[\"window\"]):\n",
    "                highlights_by_doc[doc_idx].append(item[\"sentence\"])\n",
    "                found += 1\n",
    "                if found >= MAX_SUPPORT_PER_CLAIM:\n",
    "                    break\n",
    "\n",
    "        if found >= MAX_SUPPORT_PER_CLAIM:\n",
    "            break\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "for i in highlights_by_doc:\n",
    "    highlights_by_doc[i] = list(dict.fromkeys(highlights_by_doc[i]))\n",
    "\n",
    "highlights_by_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ce76f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>mark{padding:0.08em 0.15em; border-radius:3px;}</style><h2>Answer</h2><div style='white-space: pre-wrap;'>Tower of Terror</div><hr/><h2>Retrieved Documents</h2><p>Highlights are sentences that explicitly support the claim.</p><h3>Document 0</h3><div style='white-space: pre-wrap; border: 1px solid #ddd; padding: 10px; border-radius: 6px;'>The Tower of Terror buildings are among the tallest structures found at their respective Disney resorts. <mark>At 199 feet (60.7 m), the Florida version is the second tallest attraction at the Walt Disney World Resort, with only Expedition Everest 199.5 feet (60.8 m) being taller.</mark> <mark>At the Disneyland Resort, the 183-foot (55.8 m) structure (which now houses Guardians of the Galaxy -- Mission: Breakout!) is the tallest building at the resort, as well as one of the tallest buildings in Anaheim.</mark> At Disneyland Paris, it is the second tallest attraction.</div><br/><h3>Document 1</h3><div style='white-space: pre-wrap; border: 1px solid #ddd; padding: 10px; border-radius: 6px;'>New York City, the most populous city in the United States, is home to over 6,486 completed high rise buildings of at least 35 meters, of which at least 113 completed are taller than 600 feet (183 m). The tallest building in New York is One World Trade Center, which rises 1,776 feet (541 m). The 104-story skyscraper also stands as the tallest building in the United States, the tallest building in the Western Hemisphere, and the sixth-tallest building in the world. The second-tallest building in the city is 432 Park Avenue, standing at 1,396 feet (426 m), and the third-tallest is the recently-topped-out 30 Hudson Yards. Not counting its antenna, the 4th-tallest is the 102-story Empire State Building in Midtown Manhattan, which was finished in 1931 and rises to 1,250 feet (381 m), increased to 1,454 feet (443 m) by its antenna. It is the fifth-tallest building in the United States and the 37th-tallest building in the world.</div><br/><h3>Document 2</h3><div style='white-space: pre-wrap; border: 1px solid #ddd; padding: 10px; border-radius: 6px;'>The Tokyo Skytree, completed in February 2012, reaches a height of 634 m (2,080 ft), making it the tallest tower, and second-tallest free-standing structure in the world.</div><br/><h3>Document 3</h3><div style='white-space: pre-wrap; border: 1px solid #ddd; padding: 10px; border-radius: 6px;'>Eureka Tower is a 297.3-metre (975 ft) skyscraper located in the Southbank precinct of Melbourne, Victoria, Australia. Construction began in August 2002 and the exterior completed on 1 June 2006. The plaza was finished in June 2006 and the building was officially opened on 11 October 2006. The project was designed by Melbourne architectural firm Fender Katsalidis Architects and was built by Grocon (Grollo Australia). The developer of the tower was Eureka Tower Pty Ltd, a joint venture consisting of Daniel Grollo (Grocon), investor Tab Fried and one of the Tower&#x27;s architects Nonda Katsalidis. It was the world&#x27;s tallest residential tower when measured to its highest floor, until surpassed by Ocean Heights and the HHHR Tower in Dubai. It is the second tallest building in Australia, behind Q1, Queensland, and is the tallest to roof (excluding spire). As of 2016 it is the 15th tallest residential building in the world.</div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 13: Render output\n",
    "parts = []\n",
    "parts.append(\"<style>mark{padding:0.08em 0.15em; border-radius:3px;}</style>\")\n",
    "parts.append(\"<h2>Answer</h2>\")\n",
    "parts.append(f\"<div style='white-space: pre-wrap;'>{html.escape(baseline)}</div>\")\n",
    "parts.append(\"<hr/>\")\n",
    "\n",
    "parts.append(\"<h2>Retrieved Documents</h2>\")\n",
    "parts.append(\"<p>Highlights are sentences that explicitly support the claim.</p>\")\n",
    "\n",
    "for i, d in enumerate(docs):\n",
    "    snippets = highlights_by_doc.get(i, [])\n",
    "    body = highlight_html_exact(d.page_content, snippets) if snippets else html.escape(d.page_content)\n",
    "\n",
    "    parts.append(f\"<h3>Document {i}</h3>\")\n",
    "    parts.append(\"<div style='white-space: pre-wrap; border: 1px solid #ddd; padding: 10px; border-radius: 6px;'>\")\n",
    "    parts.append(body)\n",
    "    parts.append(\"</div><br/>\")\n",
    "\n",
    "display(HTML(\"\".join(parts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a949751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_idx</th>\n",
       "      <th>highlighted_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>At 199 feet (60.7 m), the Florida version is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>At the Disneyland Resort, the 183-foot (55.8 m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_idx                               highlighted_sentence\n",
       "0        0  At 199 feet (60.7 m), the Florida version is t...\n",
       "1        0  At the Disneyland Resort, the 183-foot (55.8 m..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 14: Simple table for debugging\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for doc_idx, sents in highlights_by_doc.items():\n",
    "    for s in sents:\n",
    "        rows.append({\n",
    "            \"doc_idx\": doc_idx,\n",
    "            \"highlighted_sentence\": s\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a7b3433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Answer</h2><p>Tower of Terror</p><hr><h3>Document 0</h3><pre>The Tower of Terror buildings are among the tallest structures found at their respective Disney resorts. <mark>At 199 feet (60.7 m), the Florida version is the second tallest attraction at the Walt Disney World Resort, with only Expedition Everest 199.5 feet (60.8 m) being taller.</mark> <mark>At the Disneyland Resort, the 183-foot (55.8 m) structure (which now houses Guardians of the Galaxy -- Mission: Breakout!) is the tallest building at the resort, as well as one of the tallest buildings in Anaheim.</mark> At Disneyland Paris, it is the second tallest attraction.</pre><h3>Document 1</h3><pre>New York City, the most populous city in the United States, is home to over 6,486 completed high rise buildings of at least 35 meters, of which at least 113 completed are taller than 600 feet (183 m). The tallest building in New York is One World Trade Center, which rises 1,776 feet (541 m). The 104-story skyscraper also stands as the tallest building in the United States, the tallest building in the Western Hemisphere, and the sixth-tallest building in the world. The second-tallest building in the city is 432 Park Avenue, standing at 1,396 feet (426 m), and the third-tallest is the recently-topped-out 30 Hudson Yards. Not counting its antenna, the 4th-tallest is the 102-story Empire State Building in Midtown Manhattan, which was finished in 1931 and rises to 1,250 feet (381 m), increased to 1,454 feet (443 m) by its antenna. It is the fifth-tallest building in the United States and the 37th-tallest building in the world.</pre><h3>Document 2</h3><pre>The Tokyo Skytree, completed in February 2012, reaches a height of 634 m (2,080 ft), making it the tallest tower, and second-tallest free-standing structure in the world.</pre><h3>Document 3</h3><pre>Eureka Tower is a 297.3-metre (975 ft) skyscraper located in the Southbank precinct of Melbourne, Victoria, Australia. Construction began in August 2002 and the exterior completed on 1 June 2006. The plaza was finished in June 2006 and the building was officially opened on 11 October 2006. The project was designed by Melbourne architectural firm Fender Katsalidis Architects and was built by Grocon (Grollo Australia). The developer of the tower was Eureka Tower Pty Ltd, a joint venture consisting of Daniel Grollo (Grocon), investor Tab Fried and one of the Tower&#x27;s architects Nonda Katsalidis. It was the world&#x27;s tallest residential tower when measured to its highest floor, until surpassed by Ocean Heights and the HHHR Tower in Dubai. It is the second tallest building in Australia, behind Q1, Queensland, and is the tallest to roof (excluding spire). As of 2016 it is the 15th tallest residential building in the world.</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import html\n",
    "from IPython.display import display, HTML\n",
    "def highlight_text(text, snippets):\n",
    "    out = html.escape(text)\n",
    "    for s in snippets:\n",
    "        out = out.replace(\n",
    "            html.escape(s),\n",
    "            f\"<mark>{html.escape(s)}</mark>\"\n",
    "        )\n",
    "    return out\n",
    "\n",
    "html_out = \"<h2>Answer</h2>\"\n",
    "html_out += f\"<p>{html.escape(baseline)}</p><hr>\"\n",
    "\n",
    "for i, d in enumerate(docs):\n",
    "    html_out += f\"<h3>Document {i}</h3>\"\n",
    "    body = highlight_text(d.page_content, highlights_by_doc.get(i, []))\n",
    "    html_out += f\"<pre>{body}</pre>\"\n",
    "\n",
    "display(HTML(html_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d7d7fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highlighted sentence indices: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# We prepare helpers for removing/keeping evidence and mapping highlights to sentence indices.\n",
    "# We assume highlights mark full sentences.\n",
    "\n",
    "def mask_remove(indices, sentences):\n",
    "    return \" \".join([s for i, s in enumerate(sentences) if i not in indices])\n",
    "\n",
    "def mask_except(indices, sentences):\n",
    "    return \" \".join([s for i, s in enumerate(sentences) if i in indices])\n",
    "\n",
    "def get_highlight_indices(sentences, highlights_by_doc):\n",
    "    hl = set()\n",
    "    for doc_sents in highlights_by_doc.values():\n",
    "        for h in doc_sents:\n",
    "            for i, s in enumerate(sentences):\n",
    "                if h.strip() == s.strip():\n",
    "                    hl.add(i)\n",
    "    return sorted(list(hl))\n",
    "\n",
    "sentences_full = split_sentences(context)\n",
    "highlight_indices = get_highlight_indices(sentences_full, highlights_by_doc)\n",
    "print(\"highlighted sentence indices:\", highlight_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9c1bbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': 'Tower of Terror',\n",
       " 'comp_answer': 'Based on the provided context, there is no mention of any building being 199 feet tall. The context describes several buildings with specific heights, such as:\\n\\n- One World Trade Center at 1,776 feet\\n- 432 Park Avenue at 1,396 feet\\n- The Empire State Building at 1,250 feet (to the roof, excluding the antenna)\\n- The Tokyo Skytree at 2,080 feet\\n- Eureka Tower at 975 feet\\n\\nAdditionally, the context refers to the Tower of Terror as \"among the tallest structures\" at Disneyland Paris and notes that it is the second tallest attraction there, but it does not specify its height. No height of 199 feet is provided for any building in the context.\\n\\nSince the context does not include information about a building that is 199 feet tall, the answer cannot be determined from the given information. Therefore, based solely on the context, the building that is 199 feet tall is not specified.\\n\\n**Answer:** Unknown (not specified in the context).',\n",
       " 'suff_answer': 'unknown',\n",
       " 'comprehensiveness_drop': 1,\n",
       " 'sufficiency_drop': 1}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We measure drop when removing highlights (comprehensiveness) and when keeping only highlights (sufficiency).\n",
    "# We compare answers relative to the baseline.\n",
    "\n",
    "def answer_from_context(question, ctx):\n",
    "    p = f\"\"\"Answer using only the context.\n",
    "If the answer is missing, say unknown.\n",
    "Return only the final answer.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "{ctx}\n",
    "\n",
    "Answer:\"\"\".strip()\n",
    "    return llm.invoke(p).content.strip()\n",
    "\n",
    "def run_comp_suff(question, context, highlight_indices):\n",
    "    sentences = split_sentences(context)\n",
    "    baseline = answer_from_context(question, context)\n",
    "\n",
    "    ctx_comp = mask_remove(highlight_indices, sentences)\n",
    "    ans_comp = answer_from_context(question, ctx_comp)\n",
    "    comp_drop = 1 if ans_comp != baseline else 0\n",
    "\n",
    "    ctx_suff = mask_except(highlight_indices, sentences) if highlight_indices else \"\"\n",
    "    ans_suff = answer_from_context(question, ctx_suff) if ctx_suff else \"unknown\"\n",
    "    suff_drop = 1 if ans_suff != baseline else 0\n",
    "\n",
    "    return {\n",
    "        \"baseline\": baseline,\n",
    "        \"comp_answer\": ans_comp,\n",
    "        \"suff_answer\": ans_suff,\n",
    "        \"comprehensiveness_drop\": comp_drop,\n",
    "        \"sufficiency_drop\": suff_drop,\n",
    "    }\n",
    "\n",
    "res = run_comp_suff(question, context, highlight_indices)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e824730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fast sweep: 100%|██████████| 5/5 [1:18:00<00:00, 936.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg comprehensiveness drop: 0.8\n",
      "avg sufficiency drop: 0.8\n",
      "LLM cache — hits: 0 misses: 22 current: 22 max: 4096\n",
      "LLM calls: 22\n",
      "Total LLM time (s): 1500.24\n",
      "Avg time per LLM call (s): 68.193\n",
      "Cache hits: 0\n",
      "Cache misses: 22\n",
      "Cache size: 22 / 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Faster sweep: caching, fewer LLM calls, capped sentences, fewer questions.\n",
    "\n",
    "import random\n",
    "from statistics import mean\n",
    "from functools import lru_cache\n",
    "import time\n",
    "\n",
    "\n",
    "def get_questions_from_loader(loader, n=10):\n",
    "    \"\"\"\n",
    "    Extract n questions from BoolQ documents.\n",
    "    BoolQDataLoader.setup() returns LangChain Documents with\n",
    "    the question stored in metadata[\"question\"].\n",
    "    \"\"\"\n",
    "    docs = loader.setup()\n",
    "\n",
    "    qs = []\n",
    "    for d in docs:\n",
    "        if hasattr(d, \"metadata\") and isinstance(d.metadata, dict):\n",
    "            if \"question\" in d.metadata:\n",
    "                qs.append(d.metadata[\"question\"])\n",
    "\n",
    "    if not qs:\n",
    "        raise RuntimeError(\"No questions found in document metadata\")\n",
    "\n",
    "    return qs[:n]\n",
    "\n",
    "def candidate_sentences(docs, max_sents_per_doc):\n",
    "    \"\"\"\n",
    "    Compatibility wrapper for the fast sweep.\n",
    "    Uses the sentence windows but returns only the raw sentences.\n",
    "    \"\"\"\n",
    "    win = candidate_windows(docs, max_sents_per_doc, window_size=3)\n",
    "\n",
    "    out = {}\n",
    "    for di, items in win.items():\n",
    "        out[di] = [item[\"sentence\"] for item in items]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "llm_stats = {\n",
    "    \"calls\": 0,\n",
    "    \"total_time\": 0.0,\n",
    "}\n",
    "# global cache for any LLM call (same prompt -> instant result)\n",
    "@lru_cache(maxsize=4096)\n",
    "def llm_cached(prompt):\n",
    "    start = time.time()\n",
    "    out = llm.invoke(prompt).content.strip()\n",
    "    dt = time.time() - start\n",
    "\n",
    "    llm_stats[\"calls\"] += 1\n",
    "    llm_stats[\"total_time\"] += dt\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def answer_from_context_cached(q, ctx):\n",
    "    p = f\"\"\"Answer using only the context.\n",
    "If the answer is missing, say unknown.\n",
    "Return only the final answer.\n",
    "\n",
    "Question: {q}\n",
    "\n",
    "Context:\n",
    "{ctx}\n",
    "\n",
    "Answer:\"\"\".strip()\n",
    "    return llm_cached(p)\n",
    "\n",
    "@lru_cache(maxsize=4096)\n",
    "def support_check_cached(claim, sentence):\n",
    "    check_prompt = f\"\"\"You are verifying evidence support.\n",
    "\n",
    "Claim:\n",
    "{claim}\n",
    "\n",
    "Evidence sentence:\n",
    "{sentence}\n",
    "\n",
    "Decide if the evidence sentence explicitly supports the claim.\n",
    "Reply with exactly one token: YES or NO.\"\"\"\n",
    "    return llm_cached(check_prompt).upper().startswith(\"YES\")\n",
    "\n",
    "\n",
    "def run_one_fast(q):\n",
    "    docs = rag.retrieve_documents(q)[:TOP_K_DOCS]\n",
    "    ctx = \"\\n\\n\".join(d.page_content for d in docs if d.page_content)\n",
    "\n",
    "    baseline = answer_from_context_cached(q, ctx)\n",
    "    claims = extract_claims(baseline)\n",
    "\n",
    "    cands = candidate_sentences(docs, min(5, MAX_SENTENCES_PER_DOC))\n",
    "\n",
    "    hb = {i: [] for i in range(len(docs))}\n",
    "    for claim in claims[:1]:  # only first claim to save time\n",
    "        found = 0\n",
    "        for di, sents in cands.items():\n",
    "            for s in sents[:5]:\n",
    "                if support_check_cached(claim, s):\n",
    "                    hb[di].append(s)\n",
    "                    found += 1\n",
    "                    if found >= 1:\n",
    "                        break\n",
    "            if found >= 1:\n",
    "                break\n",
    "\n",
    "    sents_full = split_sentences(ctx)\n",
    "    idxs = get_highlight_indices(sents_full, hb)\n",
    "\n",
    "    r = run_comp_suff(q, ctx, idxs)\n",
    "    return r[\"comprehensiveness_drop\"], r[\"sufficiency_drop\"]\n",
    "\n",
    "qa_questions = get_questions_from_loader(data_loader, n=5)\n",
    "random.shuffle(qa_questions)\n",
    "\n",
    "comp_scores, suff_scores = [], []\n",
    "\n",
    "for q in tqdm(qa_questions, desc=\"fast sweep\"):\n",
    "    c, s = run_one_fast(q)\n",
    "    comp_scores.append(c)\n",
    "    suff_scores.append(s)\n",
    "\n",
    "print(\"avg comprehensiveness drop:\", round(mean(comp_scores), 3))\n",
    "print(\"avg sufficiency drop:\", round(mean(suff_scores), 3))\n",
    "info = llm_cached.cache_info()\n",
    "print(\"LLM cache — hits:\", info.hits, \"misses:\", info.misses, \"current:\", info.currsize, \"max:\", info.maxsize)\n",
    "\n",
    "info = llm_cached.cache_info()\n",
    "\n",
    "print(\"LLM calls:\", llm_stats[\"calls\"])\n",
    "print(\"Total LLM time (s):\", round(llm_stats[\"total_time\"], 2))\n",
    "print(\"Avg time per LLM call (s):\", round(llm_stats[\"total_time\"] / max(1, llm_stats[\"calls\"]), 3))\n",
    "\n",
    "print(\"Cache hits:\", info.hits)\n",
    "print(\"Cache misses:\", info.misses)\n",
    "print(\"Cache size:\", info.currsize, \"/\", info.maxsize)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
