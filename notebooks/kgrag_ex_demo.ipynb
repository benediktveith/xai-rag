{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15669d87",
   "metadata": {},
   "source": [
    "# KGRAG Ex demo: MedMCQA (medical dataset)\n",
    "\n",
    "This notebook demonstrates KGRAG Ex on MedMCQA, a medical multiple-choice dataset.\n",
    "\n",
    "Workflow:\n",
    "1. Load StatPearls as LangChain Documents.\n",
    "2. Build the vector store and retrieval setup.\n",
    "3. Build a knowledge graph from triplets extracted from the same documents.\n",
    "4. Run the KGRAG Ex pipeline and convert KG paths into pseudo paragraphs.\n",
    "5. Inspect explanations, optional perturbations, and report stats.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc041b12",
   "metadata": {},
   "source": [
    "## Notebook setup and project path\n",
    "\n",
    "Ensure the project root is on `sys.path` so local modules import correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5eb9c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/MeinNotebook/xai-rag\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = next((p for p in [Path.cwd()] + list(Path.cwd().parents) if (p / \"src\").exists()), None)\n",
    "if project_root is None:\n",
    "    raise RuntimeError('\"src\" Verzeichnis nicht gefunden. Bitte Notebook im Projekt laufen lassen.')\n",
    "\n",
    "root_str = str(project_root)\n",
    "if root_str not in sys.path:\n",
    "    sys.path.insert(0, root_str)\n",
    "\n",
    "print(\"Project root:\", project_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c8f52c",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Load data loaders, RAG components, KG builders, and the KGRAG Ex pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5a8d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "from src.modules.loader.statspearls_data_loader import StatPearlsDataLoader\n",
    "from src.modules.loader.medmcqa_data_loader import MedMCQADataLoader\n",
    "\n",
    "from src.modules.rag.rag_engine import RAGEngine\n",
    "from src.modules.llm.llm_client import LLMClient\n",
    "\n",
    "from src.modules.knowledge_graph.kg_triplet_extractor import KGTripletExtractor\n",
    "from src.modules.knowledge_graph.kg_build_service import KGBuildService\n",
    "\n",
    "from src.modules.knowledge_graph.kgrag_ex_pipeline import KGRAGExPipeline\n",
    "from src.modules.explainers.kgrag_ex_explainer import KGRAGExExplainer\n",
    "from src.modules.knowledge_graph.relation_registry import RelationRegistry, ProposedRelation, canon_relation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe9a14",
   "metadata": {},
   "source": [
    "## 1. Load StatPearls, one Document per book\n",
    "\n",
    "For a smoke test, keep only a few books and limit `max_chars_per_book`, otherwise KG building gets expensive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5c8d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StatPearls stats: StatPearlsBuildStats(tarball_downloaded=False, extracted=False, nxml_files_found=9629, jsonl_files_created=0, articles_loaded=300, chunks_emitted=13922)\n",
      "Docs: 13922\n",
      "Sample meta: {'source': 'statpearls', 'split': 'repo', 'title': 'Thrombolysis in Myocardial Infarction (TIMI) Trial, Phase I: A comparison between intravenous tissue plasminogen activator and intravenous streptokinase. Clinical findings through hospital discharge.', 'topic_name': 'Thrombolysis in Myocardial Infarction (TIMI) Trial, Phase I: A comparison between intravenous tissue plasminogen activator and intravenous streptokinase. Clinical findings through hospital discharge.', 'source_filename': 'article-100024.nxml', 'chunk_index': 0, 'chunk_id': '6de0970aebeb1d82231d62346489c3cd6ee24eebe32979badfdeae7817d4c9bb'}\n",
      "Sample preview: Thrombolysis in Myocardial Infarction (TIMI) Trial, Phase I: A comparison between intravenous tissue plasminogen activator and intravenous streptokinase. Clinical findings through hospital discharge.\n"
     ]
    }
   ],
   "source": [
    "sp_loader = StatPearlsDataLoader()\n",
    "\n",
    "statpearls_docs, sp_stats = sp_loader.setup(\n",
    "    limit_articles=300,\n",
    "    as_documents=True,\n",
    "    force_download=False,\n",
    "    force_extract=False,\n",
    "    force_rebuild_jsonl=False,\n",
    ")\n",
    "\n",
    "print(\"StatPearls stats:\", sp_stats)\n",
    "print(\"Docs:\", len(statpearls_docs))\n",
    "print(\"Sample meta:\", statpearls_docs[0].metadata)\n",
    "print(\"Sample preview:\", statpearls_docs[0].page_content[:200])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0966e",
   "metadata": {},
   "source": [
    "## 2. RAG engine setup\n",
    "\n",
    "Build a fresh Chroma vector store from the documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2b6b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 3c895ca0-86e1-414c-85f5-06a77389744a)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector store from ../data/vector_db_statpearls_kgragex...\n",
      "RagEngine ready.\n"
     ]
    }
   ],
   "source": [
    "rag = RAGEngine(persist_dir=\"../data/vector_db_statpearls_kgragex\")\n",
    "rag.setup(documents=statpearls_docs, reset=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6795505a",
   "metadata": {},
   "source": [
    "## 3. LLM client\n",
    "\n",
    "Ollama runs locally; adjust the model name to your installation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e08caae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = LLMClient(provider=\"ollama\", model_name=\"llama3.2:latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb7012",
   "metadata": {},
   "source": [
    "## 4. Build the KG from StatPearls chunks (JSONL cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34aedcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG stats: {'nodes': 1387, 'edges': 2460}\n",
      "Build stats: KGBuildStats(docs_seen=0, docs_with_triples=0, triples_forward_total=0, triples_reverse_total=0, triples_written_total=2460)\n"
     ]
    }
   ],
   "source": [
    "registry_path = Path(\"../data/relations_registry.json\")\n",
    "registry = RelationRegistry.load(registry_path)\n",
    "\n",
    "extractor = KGTripletExtractor(llm_client=client, max_retries=2, relation_registry=registry)\n",
    "kg_service = KGBuildService(extractor=extractor, relation_registry=registry, registry_cache_path=registry_path, add_reverse_edges=False)\n",
    "\n",
    "\n",
    "kg_store, kg_stats = kg_service.build_or_load(\n",
    "    docs=statpearls_docs,\n",
    "    cache_path=Path(\"../data/statpearls_kg/kg_statpearls.jsonl\"),\n",
    "    limit=13922,\n",
    "    force_rebuild=False,\n",
    "    chunk_id_prefix=\"sp\",\n",
    "    source_name=\"statpearls\",\n",
    ")\n",
    "\n",
    "print(\"KG stats:\", kg_store.stats())\n",
    "print(\"Build stats:\", kg_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e70b4",
   "metadata": {},
   "source": [
    "## 5. Quick KG stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b23a3bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 1387\n",
      "Tokens per node min/median/mean/max: 1 2.0 1.9798125450612833 9\n",
      "Nodes with >10 tokens: 0\n",
      "Example long nodes: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "nodes = [str(n) for n in kg_store.g.nodes]\n",
    "token_counts = np.array([len(n.split()) for n in nodes])\n",
    "print(\"Nodes:\", len(nodes))\n",
    "print(\"Tokens per node min/median/mean/max:\", token_counts.min(), np.median(token_counts), token_counts.mean(), token_counts.max())\n",
    "\n",
    "long_nodes = [n for n in nodes if len(n.split()) > 10]\n",
    "print(\"Nodes with >10 tokens:\", len(long_nodes))\n",
    "print(\"Example long nodes:\", long_nodes[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575aaf48",
   "metadata": {},
   "source": [
    "### Graph connectivity and relation stats\n",
    "\n",
    "Inspect connectivity, degree distribution, and relation frequencies in the KG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e2546af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 1387 Edges: 2460\n",
      "Weakly connected components: 255\n",
      "Largest component size: 633\n",
      "Degree min/median/mean/max: 2 2.0 3.5472242249459263 70\n",
      "Top relations: [('affects', 421), ('is_affected_by', 421), ('part_of', 290), ('has_part', 290), ('involves_medication', 129), ('is_involved_in_treatment', 129), ('is_detected_by', 52), ('detects', 52), ('has_occurrence_of', 49), ('occurs_in', 49), ('can_affect', 38), ('can_be_affected_by', 38)]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "G = kg_store.g\n",
    "print(\"Nodes:\", G.number_of_nodes(), \"Edges:\", G.number_of_edges())\n",
    "\n",
    "wcc = list(nx.weakly_connected_components(G)) if G.number_of_nodes() else []\n",
    "sizes = sorted([len(c) for c in wcc], reverse=True) if wcc else [0]\n",
    "print(\"Weakly connected components:\", len(wcc))\n",
    "print(\"Largest component size:\", sizes[0])\n",
    "\n",
    "deg = np.array([d for _, d in G.degree()]) if G.number_of_nodes() else np.array([0])\n",
    "print(\"Degree min/median/mean/max:\", int(deg.min()), float(np.median(deg)), float(deg.mean()), int(deg.max()))\n",
    "\n",
    "rel_counts = Counter()\n",
    "for _, _, data in G.edges(data=True):\n",
    "    rel_counts[str(data.get(\"relation\", \"Unknown\"))] += 1\n",
    "print(\"Top relations:\", rel_counts.most_common(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdfcec2",
   "metadata": {},
   "source": [
    "## 6. Pipeline and explainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa2cebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = KGRAGExPipeline(rag=rag, kg=kg_store, llm_client=client)\n",
    "explainer = KGRAGExExplainer(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea909dc6",
   "metadata": {},
   "source": [
    "## 7. Load MedMCQA, small sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43db6228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedMCQA questions: 1\n",
      "Sample question: True statements about asbestosis\n",
      "Gold: D\n"
     ]
    }
   ],
   "source": [
    "mcqa_loader = MedMCQADataLoader()\n",
    "questions = mcqa_loader.setup(split=\"train\", as_documents=True, limit=1)\n",
    "\n",
    "print(\"MedMCQA questions:\", len(questions))\n",
    "print(\"Sample question:\", questions[0].metadata.get(\"question\"))\n",
    "print(\"Gold:\", questions[0].metadata.get(\"answer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e58777a",
   "metadata": {},
   "source": [
    "## 8. Single-run test on one MedMCQA question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef0de278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to local Ollama (llama3.2:latest)...\n",
      "Question ID: b255c99a-ee84-4903-a501-35b501afeff0\n",
      "Question: True statements about asbestosis\n",
      "Gold: D\n",
      "Entities: ['asbestosis', 'disease', 'lung', 'cancer', 'risk']\n",
      "Start, End: Disease Lung\n",
      "Path length: 0\n",
      "KG context preview: \n",
      "Answer: I cannot provide information on asbestosis based on the provided context. Can I help you with something else?\n",
      "LLM calls: 1\n"
     ]
    }
   ],
   "source": [
    "d = questions[0]\n",
    "\n",
    "qid = str(d.metadata.get(\"question_id\", \"q-0\"))\n",
    "question_text = str(d.metadata.get(\"question\") or d.page_content or \"\").strip()\n",
    "gold = d.metadata.get(\"answer\")\n",
    "\n",
    "run = pipeline.run(\n",
    "    question_id=qid,\n",
    "    question=question_text,\n",
    "    gold_answer=gold,\n",
    "    entity_k=6,\n",
    "    top_k_docs=4,\n",
    ")\n",
    "\n",
    "print(\"Question ID:\", run.question_id)\n",
    "print(\"Question:\", run.question)\n",
    "print(\"Gold:\", run.gold_answer)\n",
    "print(\"Entities:\", run.entities)\n",
    "print(\"Start, End:\", run.start, run.end)\n",
    "print(\"Path length:\", len(run.path))\n",
    "print(\"KG context preview:\", (run.kg_context or \"\")[:600])\n",
    "print(\"Answer:\", run.answer)\n",
    "print(\"LLM calls:\", run.llm_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03359621",
   "metadata": {},
   "source": [
    "## 9. Optional: KG-level perturbations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c71add87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most influential node: None\n",
      "Most influential edge: None\n",
      "Most influential subpath: None\n",
      "\n",
      "First 10 perturbation outcomes:\n"
     ]
    }
   ],
   "source": [
    "report = explainer.explain(run)\n",
    "\n",
    "print(\"Most influential node:\", report.most_influential_node)\n",
    "print(\"Most influential edge:\", report.most_influential_edge)\n",
    "print(\"Most influential subpath:\", report.most_influential_subpath)\n",
    "\n",
    "print(\"\\nFirst 10 perturbation outcomes:\")\n",
    "for o in report.outcomes[:10]:\n",
    "    print({\"kind\": o.kind, \"removed\": o.removed, \"answer_changed\": o.answer_changed, \"answer\": (o.answer or \"\")[:50]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd2720",
   "metadata": {},
   "source": [
    "## 10. Mini-batch test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93a391ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>gold</th>\n",
       "      <th>path_len</th>\n",
       "      <th>entities</th>\n",
       "      <th>answer</th>\n",
       "      <th>perturbations</th>\n",
       "      <th>answer_changes</th>\n",
       "      <th>most_node</th>\n",
       "      <th>most_edge</th>\n",
       "      <th>most_subpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b255c99a-ee84-4903-a501-35b501afeff0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>asbestosis, disease, lung, cancer, risk</td>\n",
       "      <td>I cannot p</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question_id gold  path_len  \\\n",
       "0  b255c99a-ee84-4903-a501-35b501afeff0    D         0   \n",
       "\n",
       "                                  entities      answer  perturbations  \\\n",
       "0  asbestosis, disease, lung, cancer, risk  I cannot p              0   \n",
       "\n",
       "   answer_changes most_node most_edge most_subpath  \n",
       "0               0      None      None         None  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for d in questions:\n",
    "    qid = str(d.metadata.get(\"question_id\", \"q\"))\n",
    "    qtxt = str(d.metadata.get(\"question\") or d.page_content or \"\").strip()\n",
    "    gold = d.metadata.get(\"answer\")\n",
    "\n",
    "    run_i = pipeline.run(\n",
    "        question_id=qid,\n",
    "        question=qtxt,\n",
    "        gold_answer=gold,\n",
    "        entity_k=6,\n",
    "        top_k_docs=4,\n",
    "    )\n",
    "    rep_i = explainer.explain(run_i)\n",
    "    num_changed = sum(1 for o in rep_i.outcomes if o.answer_changed)\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"question_id\": run_i.question_id,\n",
    "            \"gold\": run_i.gold_answer,\n",
    "            \"path_len\": len(run_i.path),\n",
    "            \"entities\": \", \".join(run_i.entities[:6]),\n",
    "            \"answer\": (run_i.answer or \"\")[:10],\n",
    "            \"perturbations\": len(rep_i.outcomes),\n",
    "            \"answer_changes\": num_changed,\n",
    "            \"most_node\": rep_i.most_influential_node,\n",
    "            \"most_edge\": rep_i.most_influential_edge,\n",
    "            \"most_subpath\": rep_i.most_influential_subpath,\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2c735",
   "metadata": {},
   "source": [
    "## 11. Optional: compact stats for your RQs\n",
    "\n",
    "RQ2 (position proxy) depends on explainer implementation details.  \n",
    "RQ3 (node types) depends on which entity types your triplet extractor emits.  \n",
    "RQ4 (graph metrics) depends on whether your metrics module computes degree and betweenness.\n",
    "\n",
    "If your report exposes these fields, we summarize them here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f84e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "if getattr(report, \"rq2_positions\", None):\n",
    "    print(\"RQ2 positions sample:\", report.rq2_positions[:5])\n",
    "\n",
    "if getattr(report, \"rq3_node_types\", None):\n",
    "    print(\"RQ3 node types sample:\", report.rq3_node_types[:10])\n",
    "\n",
    "if getattr(report, \"rq4_graph_metrics\", None):\n",
    "    print(\"RQ4 graph metrics sample:\", report.rq4_graph_metrics[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8254f86f",
   "metadata": {},
   "source": [
    "## 12. Try your own question\n",
    "\n",
    "Use this to quickly check whether the KG has enough coverage.\n",
    "\n",
    "Note:\n",
    "If `path_len` is often 0, it's usually an entity extraction/matching or KG coverage issue, not a RAG issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22ac1942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: ['CTO', 'Cardiomyopathy']\n",
      "Start, End: CTO Cardiomyopathy\n",
      "Path length: 0\n",
      "KG context preview: A cerebrovascular accident (CTO) can have a significant impact on cardiovascular health, as it often leads to ischemia in the brain. Ischemic heart disease, characterized by reduced blood flow to the heart muscle, is a common complication of CTO and shares many risk factors with cardiomyopathy, a condition where the heart muscle becomes weakened and cannot function properly. In fact, individuals w\n",
      "Answer: CTO relates to Cardiomyopathy as a risk factor and complication.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKG context preview:\u001b[39m\u001b[33m\"\u001b[39m, (run_m.kg_context \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)[:\u001b[32m400\u001b[39m])\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAnswer:\u001b[39m\u001b[33m\"\u001b[39m, run_m.answer)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m rep_m = \u001b[43mexplainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMost influential node:\u001b[39m\u001b[33m\"\u001b[39m, rep_m.most_influential_node)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMost influential edge:\u001b[39m\u001b[33m\"\u001b[39m, rep_m.most_influential_edge)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/src/modules/explainers/kgrag_ex_explainer.py:353\u001b[39m, in \u001b[36mKGRAGExExplainer.explain\u001b[39m\u001b[34m(self, run, options, top_k_docs)\u001b[39m\n\u001b[32m    350\u001b[39m outcomes: List[PerturbationOutcome] = []\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m perturbations:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     par, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_generate_pseudo_paragraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchain_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m     ans, _, _ = \u001b[38;5;28mself\u001b[39m.pipeline._rag_answer_with_optional_kg_paragraph(\n\u001b[32m    356\u001b[39m         question=run.question,\n\u001b[32m    357\u001b[39m         kg_paragraph=par,\n\u001b[32m    358\u001b[39m         top_k_docs=top_k_docs,\n\u001b[32m    359\u001b[39m     )\n\u001b[32m    361\u001b[39m     changed = \u001b[38;5;28mbool\u001b[39m(base_answer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(ans) \u001b[38;5;129;01mand\u001b[39;00m (ans != base_answer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/src/modules/knowledge_graph/kgrag_ex_pipeline.py:190\u001b[39m, in \u001b[36mKGRAGExPipeline._generate_pseudo_paragraph\u001b[39m\u001b[34m(self, chain_str)\u001b[39m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m    168\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[33mYou are a medical instructor helping to generate educational materials.\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[33m                                                \u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m.strip()\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     resp = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m     txt = (\u001b[38;5;28mgetattr\u001b[39m(resp, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(resp)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m txt, \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:1030\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1024\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1025\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1028\u001b[39m     **kwargs: Any,\n\u001b[32m   1029\u001b[39m ) -> ChatResult:\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m   1034\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m   1035\u001b[39m         message=AIMessage(\n\u001b[32m   1036\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1043\u001b[39m         generation_info=generation_info,\n\u001b[32m   1044\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:965\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    957\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    958\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    962\u001b[39m     **kwargs: Any,\n\u001b[32m    963\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    964\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:1054\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m   1048\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1049\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   1050\u001b[39m     stop: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1051\u001b[39m     **kwargs: Any,\n\u001b[32m   1052\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m   1053\u001b[39m     reasoning = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.reasoning)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1060\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:952\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    951\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m--> \u001b[39m\u001b[32m952\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m    954\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/ollama/_client.py:181\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    178\u001b[39m   e.response.read()\n\u001b[32m    179\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpx/_models.py:929\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m decoder = LineDecoder()\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpx/_models.py:916\u001b[39m, in \u001b[36mResponse.iter_text\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    914\u001b[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpx/_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpx/_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpx/_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xai-rag/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "qid = \"manual-1\"\n",
    "question = \"How does CTO relates to Cardiomyopathy\"\n",
    "\n",
    "run_m = pipeline.run(\n",
    "    question_id=qid,\n",
    "    question=question,\n",
    "    gold_answer=None,\n",
    "    entity_k=6,\n",
    "    top_k_docs=4,\n",
    ")\n",
    "\n",
    "print(\"Entities:\", run_m.entities)\n",
    "print(\"Start, End:\", run_m.start, run_m.end)\n",
    "print(\"Path length:\", len(run_m.path))\n",
    "print(\"KG context preview:\", (run_m.kg_context or \"\")[:400])\n",
    "print(\"Answer:\", run_m.answer)\n",
    "\n",
    "rep_m = explainer.explain(run_m)\n",
    "print(\"Most influential node:\", rep_m.most_influential_node)\n",
    "print(\"Most influential edge:\", rep_m.most_influential_edge)\n",
    "print(\"Most influential subpath:\", rep_m.most_influential_subpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca67b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: ['Tension', 'pneumothorax', 'septicemia']\n",
      "Start, End: None None\n",
      "Path length: 0\n",
      "KG context preview: \n",
      "Answer: I cannot determine how tension pneumothorax relates to septicemia based on the provided context.\n",
      "Most influential node: None\n",
      "Most influential edge: None\n",
      "Most influential subpath: None\n"
     ]
    }
   ],
   "source": [
    "qid = \"manual-1\"\n",
    "question = \"How does Tension pneumothorax relates to Septicemia\"\n",
    "\n",
    "run_m = pipeline.run(\n",
    "    question_id=qid,\n",
    "    question=question,\n",
    "    gold_answer=None,\n",
    "    entity_k=6,\n",
    "    top_k_docs=4,\n",
    ")\n",
    "\n",
    "print(\"Entities:\", run_m.entities)\n",
    "print(\"Start, End:\", run_m.start, run_m.end)\n",
    "print(\"Path length:\", len(run_m.path))\n",
    "print(\"KG context preview:\", (run_m.kg_context or \"\")[:400])\n",
    "print(\"Answer:\", run_m.answer)\n",
    "\n",
    "rep_m = explainer.explain(run_m)\n",
    "print(\"Most influential node:\", rep_m.most_influential_node)\n",
    "print(\"Most influential edge:\", rep_m.most_influential_edge)\n",
    "print(\"Most influential subpath:\", rep_m.most_influential_subpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160604c",
   "metadata": {},
   "source": [
    "### Optional: print RQ metrics for the manual question\n",
    "\n",
    "Surface the RQ fields directly for quick inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b386297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sensitivity:\", rep_m.rq1_sensitivity)\n",
    "print(\"Postion:\", rep_m.rq2_positions)\n",
    "print(\"Node types:\", rep_m.rq3_node_types)\n",
    "print(\"graph_metrics:\", rep_m.rq4_graph_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f8807",
   "metadata": {},
   "source": [
    "### Debug: graph connectivity between start/end nodes\n",
    "\n",
    "Check whether the start/end nodes exist, inspect neighbors, and probe shortest paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5cb38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = kg_store.g\n",
    "start = run_m.start\n",
    "end = run_m.end\n",
    "\n",
    "print(\"start exists:\", start in G)\n",
    "print(\"end exists:\", end in G)\n",
    "\n",
    "if start in G:\n",
    "    print(\"\\nStart neighbors (out):\", list(G.successors(start))[:30])\n",
    "    print(\"Start neighbors (in):\", list(G.predecessors(start))[:30])\n",
    "\n",
    "if end in G:\n",
    "    print(\"\\nEnd neighbors (out):\", list(G.successors(end))[:30])\n",
    "    print(\"End neighbors (in):\", list(G.predecessors(end))[:30])\n",
    "\n",
    "if start in G and end in G:\n",
    "    GU = G.to_undirected(as_view=True)\n",
    "    try:\n",
    "        p = nx.shortest_path(GU, start, end)\n",
    "        print(\"\\nUndirected shortest path length:\", len(p) - 1)\n",
    "        print(\"Path nodes:\", p[:20], \"...\" if len(p) > 20 else \"\")\n",
    "    except Exception as e:\n",
    "        print(\"\\nNo undirected path:\", e)\n",
    "\n",
    "# Additional: search for similar node names\n",
    "def find_similar_nodes(q, limit=20):\n",
    "    ql = (q or \"\").lower()\n",
    "    hits = [n for n in G.nodes if ql in str(n).lower()]\n",
    "    return hits[:limit]\n",
    "\n",
    "print(\"\\nSimilar to 'CTO':\", find_similar_nodes(\"CTO\", 30))\n",
    "print(\"Similar to 'Chronic Total Occlusion':\", find_similar_nodes(\"Chronic Total Occlusion\", 30))\n",
    "print(\"Similar to 'Stroke':\", find_similar_nodes(\"Stroke\", 30))\n",
    "print(\"Similar to 'Ischemic Heart Disease':\", find_similar_nodes(\"Ischemic Heart Disease\", 30))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
